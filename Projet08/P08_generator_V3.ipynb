{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d048ce37-bbf3-464d-b179-f96612c8b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8832bb24-aef0-4e82-914c-ffa1abd8089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02906494-a4fd-4647-99a3-3be3e4db5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 11:27:54.467673: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-11 11:27:54.492242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 11:27:54.848530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6342dd-01f1-4f7b-93db-c482c7ba7c87",
   "metadata": {},
   "source": [
    "### Explore label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cca0bff-813d-41a6-a9ae-b618824dff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_from_json.csv\", sep='\\t', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293b66fe-d338-4c3a-a135-78869dc09967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>polygon</th>\n",
       "      <th>city</th>\n",
       "      <th>pic_id</th>\n",
       "      <th>set_type</th>\n",
       "      <th>target</th>\n",
       "      <th>target_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sky</td>\n",
       "      <td>[[126, 9], [235, 182], [797, 315], [1045, 339]...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>sky</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road</td>\n",
       "      <td>[[37, 561], [362, 514], [811, 398], [955, 361]...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>building</td>\n",
       "      <td>[[1140, 324], [1139, 334], [1138, 337], [1123,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>construction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vegetation</td>\n",
       "      <td>[[1129, 376], [1127, 371], [1127, 369], [1125,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>nature</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>building</td>\n",
       "      <td>[[1073, 337], [1072, 294], [1055, 291], [1049,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>construction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                            polygon    city  \\\n",
       "0         sky  [[126, 9], [235, 182], [797, 315], [1045, 339]...  lindau   \n",
       "1        road  [[37, 561], [362, 514], [811, 398], [955, 361]...  lindau   \n",
       "2    building  [[1140, 324], [1139, 334], [1138, 337], [1123,...  lindau   \n",
       "3  vegetation  [[1129, 376], [1127, 371], [1127, 369], [1125,...  lindau   \n",
       "4    building  [[1073, 337], [1072, 294], [1055, 291], [1049,...  lindau   \n",
       "\n",
       "          pic_id set_type        target  target_id  \n",
       "0  000057_000019      val           sky          5  \n",
       "1  000057_000019      val          flat          1  \n",
       "2  000057_000019      val  construction          2  \n",
       "3  000057_000019      val        nature          4  \n",
       "4  000057_000019      val  construction          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31057e9-12ed-46f9-a01d-aaf163c6d9fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/segmentation_models/__init__.py:98\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mset_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_framework\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/segmentation_models/__init__.py:67\u001b[0m, in \u001b[0;36mset_framework\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _KERAS_FRAMEWORK_NAME:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m  \u001b[38;5;66;03m# init custom objects\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/__init__.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_summary\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/vis_utils.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wrapper\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/models.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/__init__.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_source_inputs\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_arrays\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training_utils.py:17\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/metrics.py:1850\u001b[0m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1850\u001b[0m         BaseMeanIoU \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mMeanIoU\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMeanIoU\u001b[39;00m(BaseMeanIoU):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:58\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m---> 58\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.api'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/segmentation_models/__init__.py:101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     other \u001b[38;5;241m=\u001b[39m _TF_KERAS_FRAMEWORK_NAME \u001b[38;5;28;01mif\u001b[39;00m _framework \u001b[38;5;241m==\u001b[39m _KERAS_FRAMEWORK_NAME \u001b[38;5;28;01melse\u001b[39;00m _KERAS_FRAMEWORK_NAME\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mset_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSegmentation Models: using `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` framework.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(_KERAS_FRAMEWORK))\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# import helper modules\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/segmentation_models/__init__.py:71\u001b[0m, in \u001b[0;36mset_framework\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _TF_KERAS_FRAMEWORK_NAME:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtfkeras\u001b[39;00m  \u001b[38;5;66;03m# init custom objects\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot correct module name `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`, use `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` or `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     74\u001b[0m         name, _KERAS_FRAMEWORK_NAME, _TF_KERAS_FRAMEWORK_NAME))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/efficientnet/tfkeras.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_crop_and_resize\n\u001b[0;32m----> 6\u001b[0m EfficientNetB0 \u001b[38;5;241m=\u001b[39m \u001b[43minject_tfkeras_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEfficientNetB0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m EfficientNetB1 \u001b[38;5;241m=\u001b[39m inject_tfkeras_modules(model\u001b[38;5;241m.\u001b[39mEfficientNetB1)\n\u001b[1;32m      8\u001b[0m EfficientNetB2 \u001b[38;5;241m=\u001b[39m inject_tfkeras_modules(model\u001b[38;5;241m.\u001b[39mEfficientNetB2)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/efficientnet/__init__.py:50\u001b[0m, in \u001b[0;36minject_tfkeras_modules\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minject_tfkeras_modules\u001b[39m(func):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfkeras\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tfkeras\u001b[38;5;241m.\u001b[39mbackend\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e861248-3698-4745-afd6-df26b954279e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9be5f-6053-4a37-b564-020d770c61ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0a999-295f-4bba-a0cb-d8b48aebe490",
   "metadata": {},
   "outputs": [],
   "source": [
    "truc = bidule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ede2a-ac3f-41b5-8646-1a150f3c5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "import tqdm\n",
    "import cv2\n",
    "from tensorflow.python.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df8845-3074-49e2-84bf-78bda036f3b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a83783-37f0-48e0-8d17-b516375a264d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0c2de-ab75-44cf-b046-10e676b11288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9dd93-dcd4-4c27-a0da-95f02a8507d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed863bf-71f4-4177-93d2-d827d3075136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "# sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc5045-7d42-43e6-a75d-990a5ffbd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907764d2-008e-4ce8-8631-1df7fa2f6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ref: https://www.tensorflow.org/guide/gpu\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Currently, memory growth needs to be the same across GPUs\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee35e1-1e49-4c04-b339-6cbe4717cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto, InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True \n",
    "# sess = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a52ea-f264-4598-9357-3a33bc78cb65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445865d-c0ef-4fa7-b180-6026cc9c263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13734a8-e151-4736-812e-fdce7ab18461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477b85f-6601-40e5-be2e-2d32aa679b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit/train/aachen'\n",
    "mask_dir = 'P8_Cityscapes_gtFine_trainvaltest/gtFine/train/aachen'\n",
    "image_list = os.listdir(image_dir)\n",
    "mask_list = os.listdir(mask_dir)\n",
    "mask_list = [x for x in mask_list if x.endswith(\"labelIds.png\")]\n",
    "image_list.sort()\n",
    "mask_list.sort()\n",
    "print(f'. . . . .Number of images: {len(image_list)}\\n. . . . .Number of masks: {len(mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "# for i in range(len(image_list)):\n",
    "#     assert image_list[i][16:] == mask_list[i][24:]\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "samples = len(image_list)\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 256, 256\n",
    "classes = 8\n",
    "filters_n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65adb5-b762-4d17-92b3-e4456953f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seg_gen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(0, len(image_list)+1, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        drawn = 0\n",
    "        for i in idx:\n",
    "            # print(\"AAA\", len(image_list))\n",
    "            # print(\"BBB\", len(idx))\n",
    "            try:\n",
    "                _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.\n",
    "            except:\n",
    "                print(\"AAA\", len(image_list))\n",
    "                print(\"BBB\", len(idx))\n",
    "                truc = bidule\n",
    "            img = image.img_to_array(image.load_img(f'{mask_dir}/{mask_list[i]}', color_mode = \"grayscale\", target_size=(img_height, img_width)))\n",
    "            labels = np.unique(img)\n",
    "            if len(labels) < 3:\n",
    "                idx = np.random.randint(0, 50000, batch_size-drawn)\n",
    "                continue\n",
    "            img = np.squeeze(img)\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height*img_width, 8))\n",
    "            batch_y.append(mask)\n",
    "            batch_x.append(_image)\n",
    "            drawn += 1\n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5de62b-f918-4ff6-979e-c779b1a2ad65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class visualize(Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f'\\nGenerating output at epoch : {epoch}')\n",
    "        i = 567\n",
    "        img = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}'))/255.    \n",
    "        dims = img.shape\n",
    "        x = cv2.resize(img, (256, 256))\n",
    "        x = np.float32(x)/255.\n",
    "        z = unet.predict(np.expand_dims(x, axis=0))\n",
    "        z = np.squeeze(z)\n",
    "        z = z.reshape(256, 256, 8)\n",
    "        z = cv2.resize(z, (dims[1], dims[0]))\n",
    "        y = np.argmax(z, axis=2)\n",
    "        \n",
    "        construction = np.zeros_like(y)\n",
    "        human = np.zeros_like(y)\n",
    "        vehicle = np.zeros_like(y)\n",
    "        construction[y==2] = 255.\n",
    "        human[y==6] = 255.\n",
    "        vehicle[y==7] = 255.\n",
    "        \n",
    "        result = img.copy()\n",
    "        alpha = 0.4\n",
    "        img[:,:,1] = construction\n",
    "        img[:,:,2] = vehicle \n",
    "        img[:,:,0] = human\n",
    "\n",
    "        cv2.addWeighted(img, alpha, result, 1-alpha, 0, result)\n",
    "        cv2.imwrite(f'outputs/{epoch}.png', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "        print('Wrote file to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cede75-8df1-403f-9a32-7da115193f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8720d70-305d-4b3d-a32d-c3f6deabcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ee53a-1986-4a12-8a1e-175d02410ee8",
   "metadata": {},
   "source": [
    "### DilatedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541eea2-f8c6-4553-a2f2-380139c1b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Reshape, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e18ce4-d2dc-45bc-9d88-26da113a1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DilatedNet(img_height, img_width, nclasses, use_ctx_module=False, bn=False):\n",
    "    print('. . . . .Building DilatedNet. . . . .')\n",
    "    def bilinear_upsample(image_tensor):\n",
    "        # upsampled = tf.image.resize_bilinear(image_tensor, size=(img_height, img_width))\n",
    "        upsampled = tf.compat.v1.image.resize_bilinear(image_tensor, size=(img_height, img_width))\n",
    "        return upsampled\n",
    "    \n",
    "    def conv_block(conv_layers, tensor, nfilters, size=3, name='', padding='same', dilation_rate=1,pool=False):\n",
    "        if dilation_rate == 1:\n",
    "            conv_type = 'conv'\n",
    "        else:\n",
    "            conv_type = 'dilated_conv'\n",
    "        for i in range(conv_layers):\n",
    "            tensor = Conv2D(nfilters, size, padding=padding, use_bias=False, dilation_rate=dilation_rate, name=f'block{name}_{conv_type}{i+1}')(tensor)\n",
    "            if bn:\n",
    "                tensor = BatchNormalization(name=f'block{name}_bn{i+1}')(tensor)\n",
    "            tensor = Activation('relu', name=f'block{name}_relu{i+1}')(tensor)\n",
    "        if pool:\n",
    "            tensor = MaxPooling2D(2, name=f'block{name}_pool')(tensor)\n",
    "        return tensor\n",
    "       \n",
    "    nfilters = 64\n",
    "    img_input = Input(shape=(img_height, img_width, 3))\n",
    "    x = conv_block(conv_layers=2,tensor=img_input, nfilters=nfilters*1, size=3, pool=True, name=1)\n",
    "    x = conv_block(conv_layers=2,tensor=x, nfilters=nfilters*2, size=3, pool=True, name=2)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*4, size=3, pool=True, name=3)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*8, size=3, name=4)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*8, size=3,dilation_rate=2, name=5)\n",
    "    x = conv_block(conv_layers=1,tensor=x, nfilters=nfilters*64, size=7,dilation_rate=4, name='_FCN1')\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = conv_block(conv_layers=1,tensor=x, nfilters=nfilters*64, size=1, name='_FCN2')\n",
    "    x = Dropout(0.5)(x)  \n",
    "    x = Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'frontend_output')(x)\n",
    "    if use_ctx_module:\n",
    "        x = conv_block(conv_layers=2, tensor=x, nfilters=nclasses*2, size=3, name='_ctx1')\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*4, size=3, name='_ctx2', dilation_rate=2)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*8, size=3, name='_ctx3', dilation_rate=4)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*16, size=3, name='_ctx4', dilation_rate=8)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*32, size=3, name='_ctx5', dilation_rate=16)        \n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*32, size=3, name='_ctx7')\n",
    "        x = Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'ctx_output')(x)\n",
    "    x = Lambda(bilinear_upsample, name='bilinear_upsample')(x)\n",
    "    x = Reshape((img_height*img_width, nclasses))(x)\n",
    "    x = Activation('softmax', name='final_softmax')(x)\n",
    "  \n",
    "    model = Model(inputs=img_input, outputs=x, name='DilatedNet')\n",
    "    print('. . . . .Building network successful. . . . .')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69173e5-6c58-4cfb-a9f3-03094771b097",
   "metadata": {},
   "source": [
    "### Use DilatedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f8bc5-8cde-4b77-8793-21cf20f49fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = DilatedNet(256, 256, 8,use_ctx_module=True, bn=True)\n",
    "# p_unet = multi_gpu_model(unet, 4)\n",
    "# p_unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "# tb = TensorBoard(log_dir='logs', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='models-dr/pdilated.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='max', monitor='accuracy', patience=6, verbose=1)\n",
    "vis = visualize()\n",
    "# callbacks = [tb, mc, es]\n",
    "callbacks = [mc, es]\n",
    "train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f773be-420f-4e35-831e-5f3ed53e9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # p_unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "# unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "unet.fit(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "print('Saving final weights')\n",
    "unet.save_weights('dilated.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cca8bf-31e1-4979-b05b-4d3e95af1980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a919a4a2-1975-4fa0-b33e-325d6fd1f284",
   "metadata": {},
   "source": [
    "## Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efb345-261c-473f-b613-809f3b75cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Activation, Dropout, Reshape, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.python.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# multi_gpu_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fe8d6-51f0-40c1-a224-01d2ee99cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b10af-2b31-4ae3-a612-cfc7f6135c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(tensor, residual, nfilters, size=2, padding='same', strides=(2, 2)):\n",
    "    y = UpSampling2D(size=(size, size))(tensor)\n",
    "    y = Conv2D(nfilters, kernel_size=(size, size), padding=padding)(y)\n",
    "    y = concatenate([y, residual], axis=3)\n",
    "    y = conv_block(y, nfilters)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe88aae-eed9-46f6-8966-9ac8ed8e32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet(img_height, img_width, nclasses=3, filters=64):\n",
    "# down\n",
    "    input_layer = Input(shape=(img_height, img_width, 3), name='image_input')\n",
    "    conv1 = conv_block(input_layer, nfilters=filters)\n",
    "    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_block(conv1_out, nfilters=filters*2)\n",
    "    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = conv_block(conv2_out, nfilters=filters*4)\n",
    "    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = conv_block(conv3_out, nfilters=filters*8)\n",
    "    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv4_out = Dropout(0.5)(conv4_out)\n",
    "    conv5 = conv_block(conv4_out, nfilters=filters*16)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "# up\n",
    "    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n",
    "    deconv6 = Dropout(0.5)(deconv6)\n",
    "    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n",
    "    deconv7 = Dropout(0.5)(deconv7) \n",
    "    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n",
    "    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n",
    "# output\n",
    "    output_layer = Conv2D(filters=nclasses, kernel_size=(1, 1))(deconv9)\n",
    "    output_layer = BatchNormalization()(output_layer)\n",
    "    output_layer = Reshape((img_height*img_width, nclasses), input_shape=(img_height, img_width, nclasses))(output_layer)\n",
    "    output_layer = Activation('softmax')(output_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n",
    "    print('Created and loaded model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecec514-740a-4fa7-8840-81c673120fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(256, 256, nclasses=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf122d-df3c-4b21-abb2-988223cb97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08352300-696e-47a0-a05a-e5c720b0d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = seg_gen(image_list, mask_list, batch_size)\n",
    "unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f431d6-a07e-437d-a13c-8cd024f2b26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_prj08",
   "language": "python",
   "name": "conda_env_prj08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
