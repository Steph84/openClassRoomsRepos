{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d048ce37-bbf3-464d-b179-f96612c8b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8832bb24-aef0-4e82-914c-ffa1abd8089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02906494-a4fd-4647-99a3-3be3e4db5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:48:21.118162: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-07 12:48:21.141639: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 12:48:21.490386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6342dd-01f1-4f7b-93db-c482c7ba7c87",
   "metadata": {},
   "source": [
    "### Explore label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cca0bff-813d-41a6-a9ae-b618824dff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_from_json.csv\", sep='\\t', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293b66fe-d338-4c3a-a135-78869dc09967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>polygon</th>\n",
       "      <th>city</th>\n",
       "      <th>pic_id</th>\n",
       "      <th>set_type</th>\n",
       "      <th>target</th>\n",
       "      <th>target_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sky</td>\n",
       "      <td>[[126, 9], [235, 182], [797, 315], [1045, 339]...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>sky</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road</td>\n",
       "      <td>[[37, 561], [362, 514], [811, 398], [955, 361]...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>building</td>\n",
       "      <td>[[1140, 324], [1139, 334], [1138, 337], [1123,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>construction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vegetation</td>\n",
       "      <td>[[1129, 376], [1127, 371], [1127, 369], [1125,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>nature</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>building</td>\n",
       "      <td>[[1073, 337], [1072, 294], [1055, 291], [1049,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>construction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                            polygon    city  \\\n",
       "0         sky  [[126, 9], [235, 182], [797, 315], [1045, 339]...  lindau   \n",
       "1        road  [[37, 561], [362, 514], [811, 398], [955, 361]...  lindau   \n",
       "2    building  [[1140, 324], [1139, 334], [1138, 337], [1123,...  lindau   \n",
       "3  vegetation  [[1129, 376], [1127, 371], [1127, 369], [1125,...  lindau   \n",
       "4    building  [[1073, 337], [1072, 294], [1055, 291], [1049,...  lindau   \n",
       "\n",
       "          pic_id set_type        target  target_id  \n",
       "0  000057_000019      val           sky          5  \n",
       "1  000057_000019      val          flat          1  \n",
       "2  000057_000019      val  construction          2  \n",
       "3  000057_000019      val        nature          4  \n",
       "4  000057_000019      val  construction          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31057e9-12ed-46f9-a01d-aaf163c6d9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4ede2a-ac3f-41b5-8646-1a150f3c5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "import tqdm\n",
    "import cv2\n",
    "from tensorflow.python.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df8845-3074-49e2-84bf-78bda036f3b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a83783-37f0-48e0-8d17-b516375a264d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f0c2de-ab75-44cf-b046-10e676b11288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd9dd93-dcd4-4c27-a0da-95f02a8507d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed863bf-71f4-4177-93d2-d827d3075136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "# sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5edc5045-7d42-43e6-a75d-990a5ffbd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907764d2-008e-4ce8-8631-1df7fa2f6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ref: https://www.tensorflow.org/guide/gpu\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Currently, memory growth needs to be the same across GPUs\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aee35e1-1e49-4c04-b339-6cbe4717cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto, InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True \n",
    "# sess = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a52ea-f264-4598-9357-3a33bc78cb65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f445865d-c0ef-4fa7-b180-6026cc9c263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13734a8-e151-4736-812e-fdce7ab18461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9477b85f-6601-40e5-be2e-2d32aa679b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .Number of images: 174\n",
      ". . . . .Number of masks: 174\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit/train/aachen'\n",
    "mask_dir = 'P8_Cityscapes_gtFine_trainvaltest/gtFine/train/aachen'\n",
    "image_list = os.listdir(image_dir)\n",
    "mask_list = os.listdir(mask_dir)\n",
    "mask_list = [x for x in mask_list if x.endswith(\"labelIds.png\")]\n",
    "image_list.sort()\n",
    "mask_list.sort()\n",
    "print(f'. . . . .Number of images: {len(image_list)}\\n. . . . .Number of masks: {len(mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "# for i in range(len(image_list)):\n",
    "#     assert image_list[i][16:] == mask_list[i][24:]\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "samples = len(image_list)\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 256, 256\n",
    "classes = 8\n",
    "filters_n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f65adb5-b762-4d17-92b3-e4456953f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seg_gen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(0, len(image_list)+1, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        drawn = 0\n",
    "        for i in idx:\n",
    "            # print(\"AAA\", len(image_list))\n",
    "            # print(\"BBB\", len(idx))\n",
    "            try:\n",
    "                _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.\n",
    "            except:\n",
    "                print(\"AAA\", len(image_list))\n",
    "                print(\"BBB\", len(idx))\n",
    "                truc = bidule\n",
    "            img = image.img_to_array(image.load_img(f'{mask_dir}/{mask_list[i]}', color_mode = \"grayscale\", target_size=(img_height, img_width)))\n",
    "            labels = np.unique(img)\n",
    "            if len(labels) < 3:\n",
    "                idx = np.random.randint(0, 50000, batch_size-drawn)\n",
    "                continue\n",
    "            img = np.squeeze(img)\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height*img_width, 8))\n",
    "            batch_y.append(mask)\n",
    "            batch_x.append(_image)\n",
    "            drawn += 1\n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5de62b-f918-4ff6-979e-c779b1a2ad65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class visualize(Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f'\\nGenerating output at epoch : {epoch}')\n",
    "        i = 567\n",
    "        img = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}'))/255.    \n",
    "        dims = img.shape\n",
    "        x = cv2.resize(img, (256, 256))\n",
    "        x = np.float32(x)/255.\n",
    "        z = unet.predict(np.expand_dims(x, axis=0))\n",
    "        z = np.squeeze(z)\n",
    "        z = z.reshape(256, 256, 8)\n",
    "        z = cv2.resize(z, (dims[1], dims[0]))\n",
    "        y = np.argmax(z, axis=2)\n",
    "        \n",
    "        construction = np.zeros_like(y)\n",
    "        human = np.zeros_like(y)\n",
    "        vehicle = np.zeros_like(y)\n",
    "        construction[y==2] = 255.\n",
    "        human[y==6] = 255.\n",
    "        vehicle[y==7] = 255.\n",
    "        \n",
    "        result = img.copy()\n",
    "        alpha = 0.4\n",
    "        img[:,:,1] = construction\n",
    "        img[:,:,2] = vehicle \n",
    "        img[:,:,0] = human\n",
    "\n",
    "        cv2.addWeighted(img, alpha, result, 1-alpha, 0, result)\n",
    "        cv2.imwrite(f'outputs/{epoch}.png', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "        print('Wrote file to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33cede75-8df1-403f-9a32-7da115193f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8720d70-305d-4b3d-a32d-c3f6deabcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ee53a-1986-4a12-8a1e-175d02410ee8",
   "metadata": {},
   "source": [
    "### DilatedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3541eea2-f8c6-4553-a2f2-380139c1b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Reshape, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67e18ce4-d2dc-45bc-9d88-26da113a1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DilatedNet(img_height, img_width, nclasses, use_ctx_module=False, bn=False):\n",
    "    print('. . . . .Building DilatedNet. . . . .')\n",
    "    def bilinear_upsample(image_tensor):\n",
    "        # upsampled = tf.image.resize_bilinear(image_tensor, size=(img_height, img_width))\n",
    "        upsampled = tf.compat.v1.image.resize_bilinear(image_tensor, size=(img_height, img_width))\n",
    "        return upsampled\n",
    "    \n",
    "    def conv_block(conv_layers, tensor, nfilters, size=3, name='', padding='same', dilation_rate=1,pool=False):\n",
    "        if dilation_rate == 1:\n",
    "            conv_type = 'conv'\n",
    "        else:\n",
    "            conv_type = 'dilated_conv'\n",
    "        for i in range(conv_layers):\n",
    "            tensor = Conv2D(nfilters, size, padding=padding, use_bias=False, dilation_rate=dilation_rate, name=f'block{name}_{conv_type}{i+1}')(tensor)\n",
    "            if bn:\n",
    "                tensor = BatchNormalization(name=f'block{name}_bn{i+1}')(tensor)\n",
    "            tensor = Activation('relu', name=f'block{name}_relu{i+1}')(tensor)\n",
    "        if pool:\n",
    "            tensor = MaxPooling2D(2, name=f'block{name}_pool')(tensor)\n",
    "        return tensor\n",
    "       \n",
    "    nfilters = 64\n",
    "    img_input = Input(shape=(img_height, img_width, 3))\n",
    "    x = conv_block(conv_layers=2,tensor=img_input, nfilters=nfilters*1, size=3, pool=True, name=1)\n",
    "    x = conv_block(conv_layers=2,tensor=x, nfilters=nfilters*2, size=3, pool=True, name=2)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*4, size=3, pool=True, name=3)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*8, size=3, name=4)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*8, size=3,dilation_rate=2, name=5)\n",
    "    x = conv_block(conv_layers=1,tensor=x, nfilters=nfilters*64, size=7,dilation_rate=4, name='_FCN1')\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = conv_block(conv_layers=1,tensor=x, nfilters=nfilters*64, size=1, name='_FCN2')\n",
    "    x = Dropout(0.5)(x)  \n",
    "    x = Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'frontend_output')(x)\n",
    "    if use_ctx_module:\n",
    "        x = conv_block(conv_layers=2, tensor=x, nfilters=nclasses*2, size=3, name='_ctx1')\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*4, size=3, name='_ctx2', dilation_rate=2)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*8, size=3, name='_ctx3', dilation_rate=4)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*16, size=3, name='_ctx4', dilation_rate=8)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*32, size=3, name='_ctx5', dilation_rate=16)        \n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*32, size=3, name='_ctx7')\n",
    "        x = Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'ctx_output')(x)\n",
    "    x = Lambda(bilinear_upsample, name='bilinear_upsample')(x)\n",
    "    x = Reshape((img_height*img_width, nclasses))(x)\n",
    "    x = Activation('softmax', name='final_softmax')(x)\n",
    "  \n",
    "    model = Model(inputs=img_input, outputs=x, name='DilatedNet')\n",
    "    print('. . . . .Building network successful. . . . .')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69173e5-6c58-4cfb-a9f3-03094771b097",
   "metadata": {},
   "source": [
    "### Use DilatedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "280f8bc5-8cde-4b77-8793-21cf20f49fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .Building DilatedNet. . . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:48:22.207231: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-09-07 12:48:22.207259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: sle-machina\n",
      "2023-09-07 12:48:22.207267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: sle-machina\n",
      "2023-09-07 12:48:22.207368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.86.5\n",
      "2023-09-07 12:48:22.207379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.86.5\n",
      "2023-09-07 12:48:22.207382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.86.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .Building network successful. . . . .\n"
     ]
    }
   ],
   "source": [
    "unet = DilatedNet(256, 256, 8,use_ctx_module=True, bn=True)\n",
    "# p_unet = multi_gpu_model(unet, 4)\n",
    "# p_unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "# tb = TensorBoard(log_dir='logs', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='models-dr/pdilated.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='max', monitor='accuracy', patience=6, verbose=1)\n",
    "vis = visualize()\n",
    "# callbacks = [tb, mc, es]\n",
    "callbacks = [mc, es]\n",
    "train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6f773be-420f-4e35-831e-5f3ed53e9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0684 - dice_coeff: 0.5395 - accuracy: 0.6133 WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,dice_coeff,accuracy\n",
      "17/17 [==============================] - 296s 17s/step - loss: 1.0684 - dice_coeff: 0.5395 - accuracy: 0.6133\n",
      "Epoch 2/8\n",
      "AAA 174\n",
      "BBB 10\n",
      "AAA 174\n",
      "BBB 10\n",
      " 2/17 [==>...........................] - ETA: 4:27 - loss: 0.8546 - dice_coeff: 0.5833 - accuracy: 0.6507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:53:56.030067: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: NameError: name 'bidule' is not defined\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/tmp/ipykernel_36657/2703310850.py\", line 17, in __getitem__\n",
      "    _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.\n",
      "\n",
      "IndexError: list index out of range\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 871, in get\n",
      "    raise e\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 862, in get\n",
      "    inputs = self.queue.get(block=True, timeout=5).get()\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 771, in get\n",
      "    raise self._value\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "\n",
      "  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 648, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "\n",
      "  File \"/tmp/ipykernel_36657/2703310850.py\", line 21, in __getitem__\n",
      "    truc = bidule\n",
      "\n",
      "NameError: name 'bidule' is not defined\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/17 [====>.........................] - ETA: 4:09 - loss: 0.8583 - dice_coeff: 0.5808 - accuracy: 0.6531"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nNameError: name 'bidule' is not defined\nTraceback (most recent call last):\n\n  File \"/tmp/ipykernel_36657/2703310850.py\", line 17, in __getitem__\n    _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.\n\nIndexError: list index out of range\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 871, in get\n    raise e\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 862, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 648, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/tmp/ipykernel_36657/2703310850.py\", line 21, in __getitem__\n    truc = bidule\n\nNameError: name 'bidule' is not defined\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_10636]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # p_unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving final weights\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m unet\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilated.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nNameError: name 'bidule' is not defined\nTraceback (most recent call last):\n\n  File \"/tmp/ipykernel_36657/2703310850.py\", line 17, in __getitem__\n    _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.\n\nIndexError: list index out of range\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 871, in get\n    raise e\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 862, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/home/slerendu/anaconda3/lib/python3.9/site-packages/keras/src/utils/data_utils.py\", line 648, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/tmp/ipykernel_36657/2703310850.py\", line 21, in __getitem__\n    truc = bidule\n\nNameError: name 'bidule' is not defined\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_10636]"
     ]
    }
   ],
   "source": [
    "# # p_unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "# unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "unet.fit(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "print('Saving final weights')\n",
    "unet.save_weights('dilated.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cca8bf-31e1-4979-b05b-4d3e95af1980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a919a4a2-1975-4fa0-b33e-325d6fd1f284",
   "metadata": {},
   "source": [
    "## Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efb345-261c-473f-b613-809f3b75cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Activation, Dropout, Reshape, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.python.keras.optimizers import Adadelta, Nadam\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# multi_gpu_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fe8d6-51f0-40c1-a224-01d2ee99cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b10af-2b31-4ae3-a612-cfc7f6135c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(tensor, residual, nfilters, size=2, padding='same', strides=(2, 2)):\n",
    "    y = UpSampling2D(size=(size, size))(tensor)\n",
    "    y = Conv2D(nfilters, kernel_size=(size, size), padding=padding)(y)\n",
    "    y = concatenate([y, residual], axis=3)\n",
    "    y = conv_block(y, nfilters)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe88aae-eed9-46f6-8966-9ac8ed8e32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet(img_height, img_width, nclasses=3, filters=64):\n",
    "# down\n",
    "    input_layer = Input(shape=(img_height, img_width, 3), name='image_input')\n",
    "    conv1 = conv_block(input_layer, nfilters=filters)\n",
    "    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_block(conv1_out, nfilters=filters*2)\n",
    "    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = conv_block(conv2_out, nfilters=filters*4)\n",
    "    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = conv_block(conv3_out, nfilters=filters*8)\n",
    "    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv4_out = Dropout(0.5)(conv4_out)\n",
    "    conv5 = conv_block(conv4_out, nfilters=filters*16)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "# up\n",
    "    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n",
    "    deconv6 = Dropout(0.5)(deconv6)\n",
    "    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n",
    "    deconv7 = Dropout(0.5)(deconv7) \n",
    "    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n",
    "    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n",
    "# output\n",
    "    output_layer = Conv2D(filters=nclasses, kernel_size=(1, 1))(deconv9)\n",
    "    output_layer = BatchNormalization()(output_layer)\n",
    "    output_layer = Reshape((img_height*img_width, nclasses), input_shape=(img_height, img_width, nclasses))(output_layer)\n",
    "    output_layer = Activation('softmax')(output_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n",
    "    print('Created and loaded model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecec514-740a-4fa7-8840-81c673120fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(256, 256, nclasses=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf122d-df3c-4b21-abb2-988223cb97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08352300-696e-47a0-a05a-e5c720b0d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = seg_gen(image_list, mask_list, batch_size)\n",
    "unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f431d6-a07e-437d-a13c-8cd024f2b26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_prj08",
   "language": "python",
   "name": "conda_env_prj08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
