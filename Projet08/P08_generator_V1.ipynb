{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d048ce37-bbf3-464d-b179-f96612c8b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02906494-a4fd-4647-99a3-3be3e4db5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 11:52:46.009425: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-31 11:52:46.033209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 11:52:46.396598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39079f-b162-43de-9a88-10d955a7534c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df909a-a52e-42f5-b3a2-7d276a1bc931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "720a185b-5104-49e4-b854-14b6eee94e7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MY_Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79ffaf9-a99b-4893-816b-9af7991957af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MY_Generator(tf.keras.utils.Sequence):\n",
    "\n",
    "#     def __init__(self, image_filenames, labels, batch_size):\n",
    "#         self.image_filenames, self.labels = image_filenames, labels\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return np.ceil(len(self.image_filenames) / float(self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "#         batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "#         return np.array([\n",
    "#             resize(imread(file_name), (200, 200))\n",
    "#                for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379c328-1abf-4b2c-820f-1b1a754ebb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_training_batch_generator = My_Generator(training_filenames, GT_training, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6342dd-01f1-4f7b-93db-c482c7ba7c87",
   "metadata": {},
   "source": [
    "### Explore label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cca0bff-813d-41a6-a9ae-b618824dff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data_from_json.csv\", sep='\\t', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293b66fe-d338-4c3a-a135-78869dc09967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>polygon</th>\n",
       "      <th>city</th>\n",
       "      <th>pic_id</th>\n",
       "      <th>set_type</th>\n",
       "      <th>target</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sky</td>\n",
       "      <td>[[126, 9], [235, 182], [797, 315], [1045, 339]...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>sky</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road</td>\n",
       "      <td>[[37, 561], [362, 514], [811, 398], [955, 361]...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>building</td>\n",
       "      <td>[[1140, 324], [1139, 334], [1138, 337], [1123,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>construction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vegetation</td>\n",
       "      <td>[[1129, 376], [1127, 371], [1127, 369], [1125,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>nature</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>building</td>\n",
       "      <td>[[1073, 337], [1072, 294], [1055, 291], [1049,...</td>\n",
       "      <td>lindau</td>\n",
       "      <td>000057_000019</td>\n",
       "      <td>val</td>\n",
       "      <td>construction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                            polygon    city  \\\n",
       "0         sky  [[126, 9], [235, 182], [797, 315], [1045, 339]...  lindau   \n",
       "1        road  [[37, 561], [362, 514], [811, 398], [955, 361]...  lindau   \n",
       "2    building  [[1140, 324], [1139, 334], [1138, 337], [1123,...  lindau   \n",
       "3  vegetation  [[1129, 376], [1127, 371], [1127, 369], [1125,...  lindau   \n",
       "4    building  [[1073, 337], [1072, 294], [1055, 291], [1049,...  lindau   \n",
       "\n",
       "          pic_id set_type        target  label_id  \n",
       "0  000057_000019      val           sky         5  \n",
       "1  000057_000019      val          flat         1  \n",
       "2  000057_000019      val  construction         2  \n",
       "3  000057_000019      val        nature         4  \n",
       "4  000057_000019      val  construction         2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31057e9-12ed-46f9-a01d-aaf163c6d9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a634d65-829b-4bca-a6ea-b9e8df77a045",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4ede2a-ac3f-41b5-8646-1a150f3c5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "import tqdm\n",
    "import cv2\n",
    "from tensorflow.python.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f445865d-c0ef-4fa7-b180-6026cc9c263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + (3*dice_loss(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f13734a8-e151-4736-812e-fdce7ab18461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {'void': [0, 1, 2, 3, 4, 5, 6],\n",
    " 'flat': [7, 8, 9, 10],\n",
    " 'construction': [11, 12, 13, 14, 15, 16],\n",
    " 'object': [17, 18, 19, 20],\n",
    " 'nature': [21, 22],\n",
    " 'sky': [23],\n",
    " 'human': [24, 25],\n",
    " 'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9477b85f-6601-40e5-be2e-2d32aa679b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .Number of images: 174\n",
      ". . . . .Number of masks: 174\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit/train/aachen'\n",
    "mask_dir = 'P8_Cityscapes_gtFine_trainvaltest/gtFine/train/aachen'\n",
    "image_list = os.listdir(image_dir)\n",
    "mask_list = os.listdir(mask_dir)\n",
    "mask_list = [x for x in mask_list if x.endswith(\"labelIds.png\")]\n",
    "image_list.sort()\n",
    "mask_list.sort()\n",
    "print(f'. . . . .Number of images: {len(image_list)}\\n. . . . .Number of masks: {len(mask_list)}')\n",
    "\n",
    "# sanity check\n",
    "# for i in range(len(image_list)):\n",
    "#     assert image_list[i][16:] == mask_list[i][24:]\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "samples = 50000\n",
    "steps = samples//batch_size\n",
    "img_height, img_width = 256, 256\n",
    "classes = 8\n",
    "filters_n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f65adb5-b762-4d17-92b3-e4456953f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seg_gen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(0, 50000, batch_size)\n",
    "        batch_x, batch_y = [], []\n",
    "        drawn = 0\n",
    "        for i in idx:\n",
    "            _image = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}', target_size=(img_height, img_width)))/255.   \n",
    "            img = image.img_to_array(image.load_img(f'{mask_dir}/{mask_list[i]}', grayscale=True, target_size=(img_height, img_width)))\n",
    "            labels = np.unique(img)\n",
    "            if len(labels) < 3:\n",
    "                idx = np.random.randint(0, 50000, batch_size-drawn)\n",
    "                continue\n",
    "            img = np.squeeze(img)\n",
    "            mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "            for i in range(-1, 34):\n",
    "                if i in cats['void']:\n",
    "                    mask[:,:,0] = np.logical_or(mask[:,:,0],(img==i))\n",
    "                elif i in cats['flat']:\n",
    "                    mask[:,:,1] = np.logical_or(mask[:,:,1],(img==i))\n",
    "                elif i in cats['construction']:\n",
    "                    mask[:,:,2] = np.logical_or(mask[:,:,2],(img==i))\n",
    "                elif i in cats['object']:\n",
    "                    mask[:,:,3] = np.logical_or(mask[:,:,3],(img==i))\n",
    "                elif i in cats['nature']:\n",
    "                    mask[:,:,4] = np.logical_or(mask[:,:,4],(img==i))\n",
    "                elif i in cats['sky']:\n",
    "                    mask[:,:,5] = np.logical_or(mask[:,:,5],(img==i))\n",
    "                elif i in cats['human']:\n",
    "                    mask[:,:,6] = np.logical_or(mask[:,:,6],(img==i))\n",
    "                elif i in cats['vehicle']:\n",
    "                    mask[:,:,7] = np.logical_or(mask[:,:,7],(img==i))\n",
    "            mask = np.resize(mask,(img_height*img_width, 8))\n",
    "            batch_y.append(mask)\n",
    "            batch_x.append(_image)\n",
    "            drawn += 1\n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5de62b-f918-4ff6-979e-c779b1a2ad65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class visualize(Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(f'\\nGenerating output at epoch : {epoch}')\n",
    "        i = 567\n",
    "        img = image.img_to_array(image.load_img(f'{image_dir}/{image_list[i]}'))/255.    \n",
    "        dims = img.shape\n",
    "        x = cv2.resize(img, (256, 256))\n",
    "        x = np.float32(x)/255.\n",
    "        z = unet.predict(np.expand_dims(x, axis=0))\n",
    "        z = np.squeeze(z)\n",
    "        z = z.reshape(256, 256, 8)\n",
    "        z = cv2.resize(z, (dims[1], dims[0]))\n",
    "        y = np.argmax(z, axis=2)\n",
    "        \n",
    "        construction = np.zeros_like(y)\n",
    "        human = np.zeros_like(y)\n",
    "        vehicle = np.zeros_like(y)\n",
    "        construction[y==2] = 255.\n",
    "        human[y==6] = 255.\n",
    "        vehicle[y==7] = 255.\n",
    "        \n",
    "        result = img.copy()\n",
    "        alpha = 0.4\n",
    "        img[:,:,1] = construction\n",
    "        img[:,:,2] = vehicle \n",
    "        img[:,:,0] = human\n",
    "\n",
    "        cv2.addWeighted(img, alpha, result, 1-alpha, 0, result)\n",
    "        cv2.imwrite(f'outputs/{epoch}.png', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "        print('Wrote file to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cede75-8df1-403f-9a32-7da115193f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8720d70-305d-4b3d-a32d-c3f6deabcfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.seg_gen at 0x7f5bdc643dc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3541eea2-f8c6-4553-a2f2-380139c1b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Reshape, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e18ce4-d2dc-45bc-9d88-26da113a1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DilatedNet(img_height, img_width, nclasses, use_ctx_module=False, bn=False):\n",
    "    print('. . . . .Building DilatedNet. . . . .')\n",
    "    def bilinear_upsample(image_tensor):\n",
    "        # upsampled = tf.image.resize_bilinear(image_tensor, size=(img_height, img_width))\n",
    "        upsampled = tf.compat.v1.image.resize_bilinear(image_tensor, size=(img_height, img_width))\n",
    "        return upsampled\n",
    "    \n",
    "    def conv_block(conv_layers, tensor, nfilters, size=3, name='', padding='same', dilation_rate=1,pool=False):\n",
    "        if dilation_rate == 1:\n",
    "            conv_type = 'conv'\n",
    "        else:\n",
    "            conv_type = 'dilated_conv'\n",
    "        for i in range(conv_layers):\n",
    "            tensor = Conv2D(nfilters, size, padding=padding, use_bias=False, dilation_rate=dilation_rate, name=f'block{name}_{conv_type}{i+1}')(tensor)\n",
    "            if bn:\n",
    "                tensor = BatchNormalization(name=f'block{name}_bn{i+1}')(tensor)\n",
    "            tensor = Activation('relu', name=f'block{name}_relu{i+1}')(tensor)\n",
    "        if pool:\n",
    "            tensor = MaxPooling2D(2, name=f'block{name}_pool')(tensor)\n",
    "        return tensor\n",
    "       \n",
    "    nfilters = 64\n",
    "    img_input = Input(shape=(img_height, img_width, 3))\n",
    "    x = conv_block(conv_layers=2,tensor=img_input, nfilters=nfilters*1, size=3, pool=True, name=1)\n",
    "    x = conv_block(conv_layers=2,tensor=x, nfilters=nfilters*2, size=3, pool=True, name=2)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*4, size=3, pool=True, name=3)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*8, size=3, name=4)\n",
    "    x = conv_block(conv_layers=3,tensor=x, nfilters=nfilters*8, size=3,dilation_rate=2, name=5)\n",
    "    x = conv_block(conv_layers=1,tensor=x, nfilters=nfilters*64, size=7,dilation_rate=4, name='_FCN1')\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = conv_block(conv_layers=1,tensor=x, nfilters=nfilters*64, size=1, name='_FCN2')\n",
    "    x = Dropout(0.5)(x)  \n",
    "    x = Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'frontend_output')(x)\n",
    "    if use_ctx_module:\n",
    "        x = conv_block(conv_layers=2, tensor=x, nfilters=nclasses*2, size=3, name='_ctx1')\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*4, size=3, name='_ctx2', dilation_rate=2)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*8, size=3, name='_ctx3', dilation_rate=4)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*16, size=3, name='_ctx4', dilation_rate=8)\n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*32, size=3, name='_ctx5', dilation_rate=16)        \n",
    "        x = conv_block(conv_layers=1, tensor=x, nfilters=nclasses*32, size=3, name='_ctx7')\n",
    "        x = Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'ctx_output')(x)\n",
    "    x = Lambda(bilinear_upsample, name='bilinear_upsample')(x)\n",
    "    x = Reshape((img_height*img_width, nclasses))(x)\n",
    "    x = Activation('softmax', name='final_softmax')(x)\n",
    "  \n",
    "    model = Model(inputs=img_input, outputs=x, name='DilatedNet')\n",
    "    print('. . . . .Building network successful. . . . .')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "280f8bc5-8cde-4b77-8793-21cf20f49fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .Building DilatedNet. . . . .\n",
      ". . . . .Building network successful. . . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 12:35:18.121067: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-08-31 12:35:18.121085: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-08-31 12:35:18.122607: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1671] Profiler found 1 GPUs\n",
      "2023-08-31 12:35:18.248332: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-08-31 12:35:18.248544: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1805] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "unet = DilatedNet(256, 256, 8,use_ctx_module=True, bn=True)\n",
    "# p_unet = multi_gpu_model(unet, 4)\n",
    "# p_unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "unet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[dice_coeff, 'accuracy'])\n",
    "tb = TensorBoard(log_dir='logs', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='models-dr/pdilated.h5', monitor='acc', save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='max', monitor='acc', patience=6, verbose=1)\n",
    "vis = visualize()\n",
    "callbacks = [tb, mc, es]\n",
    "train_gen = seg_gen(image_list, mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6f773be-420f-4e35-831e-5f3ed53e9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42823/1447523711.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # p_unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving final weights\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m unet\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilated.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mseg_gen.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m drawn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx:\n\u001b[0;32m---> 14\u001b[0m     _image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(image\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mimage_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(img_height, img_width)))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m   \n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(image\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_list[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(img_height, img_width)))\n\u001b[1;32m     16\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(img)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# # p_unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "unet.fit_generator(train_gen, steps_per_epoch=steps, epochs=8, callbacks=callbacks, workers=8)\n",
    "print('Saving final weights')\n",
    "unet.save_weights('dilated.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588043b-c099-445d-8224-86221ebb5466",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c33501-b7ca-4435-9440-b11f06ef1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            # X[i,] = np.load('data/' + ID + '.npy')\n",
    "            img_path = os.path.join('P8_Cityscapes_gtFine_trainvaltest/gtFine/train/aachen/' + ID + '.png')\n",
    "            X[i,] = np.array(Image.open(img_path))\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74736d1-72e0-4bb8-be2b-2771f0d41349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (32,32,32),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 8,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "# partition = # IDs\n",
    "# labels = # Labels\n",
    "\n",
    "# Generators\n",
    "\n",
    "training_generator = DataGenerator(image_list, mask_list, **params)\n",
    "# validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "# Design model\n",
    "# model = Sequential()\n",
    "# [...] # Architecture\n",
    "# model.compile()\n",
    "\n",
    "# # Train model on dataset\n",
    "# model.fit_generator(generator=training_generator,\n",
    "#                     validation_data=validation_generator,\n",
    "#                     use_multiprocessing=True,\n",
    "#                     workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95a3b27d-c477-44b1-b466-f580662efc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataGenerator at 0x7f5bdc4be9a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329facfa-d35a-4576-ae92-6ae53dfb9aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_prj08",
   "language": "python",
   "name": "conda_env_prj08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
