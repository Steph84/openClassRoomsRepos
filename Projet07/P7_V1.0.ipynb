{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd238a40-9d8c-4d6f-ac02-fb9082ba83d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485e8be7-23ed-4780-8aac-8001b09df5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8ddae5-db2a-47aa-a542-546706c712a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/slerendu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# pour traitement du language (NLP)\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk import tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae96e44-c262-4c86-b9c6-809de93e0fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5065e53d-91a3-4ca1-87e4-5f4b0085b718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pour les pie charts, pour afficher les pourcentages et les libellés uniquement avec le taux > limit_perc%\n",
    "limit_perc = 5\n",
    "def show_perc(pct):\n",
    "    \"\"\" Affiche le pourcentage de chaque portion si la condition est vérifiée \"\"\"\n",
    "    return ('%.1f%%' % pct) if pct > limit_perc else ''\n",
    "\n",
    "def show_labels(data):\n",
    "    list = []\n",
    "    for val, cnt in data.items():\n",
    "        if (cnt*100/np.sum(data)) > limit_perc :\n",
    "            list.append(val)\n",
    "        else:\n",
    "            list.append('')\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349552c8-39e4-4400-8ae7-1885eacd2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique_values(df, col, display_pie=True, silent=False):\n",
    "    \"\"\"\n",
    "    Affiche la liste des valeurs uniques contenues dans une colonne\n",
    "    Affiche le pie chart de ces données également\n",
    "    \"\"\"\n",
    "    temp_val_count = df[col].value_counts(normalize=True)\n",
    "    df_val_count = temp_val_count.rename_axis(\"label\").to_frame(\"%\")\n",
    "    df_val_count[\"%\"] = round(df_val_count[\"%\"]*100, 2)\n",
    "    df_val_count[\"%_cumul\"] = df_val_count[\"%\"].cumsum()\n",
    "    # afficher la majeur partie des catégories\n",
    "    sub_display = df_val_count.loc[df_val_count[\"%_cumul\"] <= 85, :]\n",
    "    \n",
    "    if silent:\n",
    "        return sub_display\n",
    "    \n",
    "    if len(sub_display) < 5:\n",
    "        display(df_val_count.head())\n",
    "    else:\n",
    "        display(sub_display.head(len(sub_display)))\n",
    "    if display_pie:\n",
    "        temp_val_count.plot(kind='pie', autopct=show_perc, labels=show_labels(temp_val_count), label='')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    return sub_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7102a8d-0820-426a-be51-096db8e403b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Méthodes pour preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba90338e-84d7-4e7c-bca2-ae6bc0ebfaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Return the corresponding character for a word use in the lemmatization\n",
    "    \n",
    "    Parameters:\n",
    "    word (str): a word\n",
    "    \n",
    "    Returns:\n",
    "    str: the corresponding character\n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82505d9-2ace-4ed9-bf3d-2aa93772f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailled_lemmatizer(sentence):\n",
    "    \"\"\"Lemmatize a sentence and return it\n",
    "    \n",
    "    Parameters:\n",
    "    sentence (list(str)): a list of words\n",
    "    \n",
    "    Returns:\n",
    "    (list(str)): a list of lemmatized words\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    result = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in sentence]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554db83d-81ab-412e-8723-7d1c4d8f5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(X):\n",
    "    X = X.split()\n",
    "    X_wo_arobas = [x for x in X if not x.startswith(\"@\")]\n",
    "    X_new = [x for x in X_wo_arobas if not x.startswith(\"http\")]\n",
    "    return ' '.join(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74bb43d8-cea3-4cee-9a96-f3f9537a2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_words(df, col, stem_or_lemma=\"stem\", debug=False):\n",
    "    \"\"\"Compute all the basics string tranformations in NLP\n",
    "    Normalisation, Tokenization, Remove of stopwords, Stemmation or Lemmatization\n",
    "    \n",
    "    Parameters:\n",
    "    df (dataframe): input dataframe\n",
    "    col (str): column to process\n",
    "    stem_or_lemma (str): choose between stemmation or lemmatization\n",
    "    debug (bool): show debug elements\n",
    "    \n",
    "    Returns:\n",
    "    list(list(str)): return a list of document. Each document is a list of words\n",
    "    \"\"\"\n",
    "    result = []    \n",
    "    # building stopwords list\n",
    "    stopW = stopwords.words('english')\n",
    "    stopW.extend(string.punctuation)\n",
    "    \n",
    "    for index, row in df.iterrows():        \n",
    "        temp_res = \"\"\n",
    "        # normalisation\n",
    "        temp_res = row[col].lower()\n",
    "        # tokenization\n",
    "        temp_res = tokenize.word_tokenize(temp_res)\n",
    "        # remove stopwords\n",
    "        temp_res = [word for word in temp_res if word not in stopW]\n",
    "        \n",
    "        # stemmation or lemmatization\n",
    "        if stem_or_lemma == \"stem\":\n",
    "            stemmer = PorterStemmer()\n",
    "            temp_res = [stemmer.stem(elt) for elt in temp_res]\n",
    "        elif stem_or_lemma == \"lemma\":\n",
    "            temp_res = detailled_lemmatizer(temp_res)\n",
    "            # lemmatizer = WordNetLemmatizer()\n",
    "            # temp_res = [lemmatizer.lemmatize(elt) for elt in temp_res]\n",
    "        else:\n",
    "            print(\"stem or lemma only\")\n",
    "        \n",
    "        result.append(temp_res)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3f2b8e-aa82-4021-9a23-f0d35960a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pos_tag(df, col, tags_to_remove=[], debug=False):\n",
    "    \"\"\"Filter words from a list of Part-Of-Speech tags\n",
    "    \n",
    "    Parameters:\n",
    "    df (dataframe): input dataframe\n",
    "    col (str): column to process\n",
    "    tags_to_remove list(str): a list of POS tag\n",
    "    debug (bool): show debug elements\n",
    "    \n",
    "    Returns:\n",
    "    list(list(str)): return a list of document. Each document is a list of words    \n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if not tags_to_remove:\n",
    "        print(\"Aucun filtre n'a été défini.\")\n",
    "        return df[col]\n",
    "    for index, row in df.iterrows():\n",
    "        temp_res = pos_tag(row[col])\n",
    "        temp_res = [x for x in temp_res if x[1] not in tags_to_remove]\n",
    "        # if debug:\n",
    "        #     print(temp_res[0])\n",
    "        result.append([x[0] for x in temp_res])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6166a297-a740-40d8-ab7e-a02ffe94f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_exclude_words(df, col, words_to_exclude=[], debug=False):\n",
    "    \"\"\"Filter words from a list of specific words\n",
    "    \n",
    "    Parameters:\n",
    "    df (dataframe): input dataframe\n",
    "    col (str): column to process\n",
    "    words_to_exclude list(str): a list of words\n",
    "    debug (bool): show debug elements\n",
    "    \n",
    "    Returns:\n",
    "    list(list(str)): return a list of document. Each document is a list of words    \n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if not words_to_exclude:\n",
    "        print(\"Aucun mots à exclure.\")\n",
    "        return df[col]\n",
    "    for index, row in df.iterrows():\n",
    "        result.append([x for x in row[col] if x not in words_to_exclude])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e5976d-f627-4ef3-adcd-b4eebce2e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_wordcloud(corpus, debug=False):\n",
    "    \"\"\"Display a WordCloud picture from a corpus\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (dict): a Counter dictionary with the frequency of each words\n",
    "    debug (bool): show debug elements\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    wordcloud = WordCloud(\n",
    "            random_state = 42,\n",
    "            normalize_plurals = False,\n",
    "            width = 600, \n",
    "            height= 300,\n",
    "            max_words = 100,\n",
    "            stopwords = [],\n",
    "            colormap=\"BrBG\")\n",
    "\n",
    "    wordcloud.generate_from_frequencies(corpus)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize = (12,8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e76c55-ee49-4f2c-8a28-a170a44847d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Méthodes pour BOW and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aff3b59-96e8-4770-8e9a-a4296e64c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation_by_tf_idf(corpus):\n",
    "    \"\"\"Compute corpus into a tf-idf vectorisation\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (list(list(str)): a list of documents\n",
    "    \n",
    "    Returns:\n",
    "    a matrix of TF-IDF features\n",
    "    the list of features names\n",
    "    \"\"\"\n",
    "    vect = TfidfVectorizer(ngram_range=(1, 1))\n",
    "    tfidf_mat = vect.fit_transform(corpus)\n",
    "    features_names = vect.get_feature_names_out()\n",
    "    return tfidf_mat, features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59567c9-0a27-48eb-a852-596d7ce4a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation_by_word2vec(simplified_documents):\n",
    "    \"\"\"Compute corpus into a Word2vec vectorisation\n",
    "    \n",
    "    Parameters:\n",
    "    simplified_documents (list(list(str)): a list of documents\n",
    "    \n",
    "    Returns:\n",
    "    the model trained\n",
    "    \"\"\"\n",
    "    model_W2V = Word2Vec(sentences=simplified_documents, vector_size=100, window=5, min_count=300, workers=4)\n",
    "    model_W2V.train(simplified_documents, total_examples=len(simplified_documents), epochs=50)\n",
    "    return model_W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae9d65cd-7ae9-488b-a983-3388a22ea64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tsne_plot(model):\n",
    "    \"\"\"Display a t-SNE plot from Word Embedding transformation\n",
    "    \n",
    "    Parameters:\n",
    "    model : the Word2vec model trained\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    word_labels = []\n",
    "    tokens = np.empty((0,100), dtype='f')\n",
    "\n",
    "    for wrd_score in model.wv.key_to_index:\n",
    "        wrd_vector = model.wv[wrd_score]\n",
    "        word_labels.append(wrd_score)\n",
    "        tokens = np.append(tokens, np.array([wrd_vector]), axis=0)\n",
    "\n",
    "    tsne_model = TSNE(perplexity=tokens.shape[0]-1, n_components=2, init='pca', n_iter=2500, random_state=42)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 8)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(word_labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e68972-f0ca-4b49-b7ef-d691af97a1e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Méthodes pour la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60f33d5-0190-4fe1-83c4-585315c7dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(actual_class, predict_class, display_labels=None):\n",
    "    \"\"\"display the confusion matrix\n",
    "    \n",
    "    Parameters:\n",
    "    actual_class : serie of the actual classes\n",
    "    predict_class : serie of the predicted classes\n",
    "    display_labels list(str)) : list of labels to show in the confusion matrix\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Calcul et affichage de la matrice de confusion\")\n",
    "    # pour calculer la matrice de confusion\n",
    "    cm = metrics.confusion_matrix(actual_class, predict_class)#, labels=display_labels)\n",
    "    cm = cm.T\n",
    "    \n",
    "    # pour afficher la matrice de confusion\n",
    "    displ = metrics.ConfusionMatrixDisplay(cm, display_labels=display_labels)\n",
    "    displ.plot()\n",
    "    displ.ax_.xaxis.tick_top()\n",
    "    displ.ax_.xaxis.set_label_position('top') \n",
    "    plt.xlabel('Actual Label')\n",
    "    plt.ylabel('Predicted Label')\n",
    "    plt.gcf().axes[0].tick_params()\n",
    "    plt.gcf().axes[1].tick_params()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e900fd-a1e8-47a4-a035-847f74861fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_report(actual_class, predict_class, display_labels=None):\n",
    "    print(\"Calcul et affichage du rapport de classification\")\n",
    "    clf_report = metrics.classification_report(actual_class, predict_class, target_names=display_labels)\n",
    "    print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae31a52-0f05-4dc6-8b99-7037fe4a3347",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd2ddc3-6e11-4c0f-8e81-6c81c36309b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/training.1600000.processed.noemoticon.csv\", sep=',',\n",
    "                   encoding=\"ISO-8859-1\", names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad9d78c-5306-48ab-8f47-103b8aaeaa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag   \n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba72c88d-faa9-4547-83ae-bea711670e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>%_cumul</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          %  %_cumul\n",
       "label               \n",
       "0      50.0     50.0\n",
       "4      50.0    100.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>%_cumul</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          %  %_cumul\n",
       "label               \n",
       "0      50.0     50.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_unique_values(data, \"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc883ec4-c007-4b36-a30b-23e5f1fb111f",
   "metadata": {},
   "source": [
    "Sentiment du tweet 0 pour négatif et 4 pour positif  \n",
    "Dans tous les cas, nous n'avons besoin que du texte du tweet et de la target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74278305-d24c-4c46-838c-ccfd29c49472",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"id\", \"date\", \"flag\", \"user\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5f92b1-1166-4eca-a952-37f3e71819a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is containing 1600000 lines and 2 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset is containing\", data.shape[0], \"lines and\", data.shape[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801865c-59ae-46a5-b389-ee8ac26914dc",
   "metadata": {},
   "source": [
    "On commence par prendre un échantillon des données dans un premier temps : 10 000 de chaque target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4dd08e-3804-474c-a259-76a0284f792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = data.groupby(['target']).apply(pd.DataFrame.sample, n=10000, replace=True, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d183c0f8-a419-4f20-a275-1ef20317b92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample dataset is containing 20000 lines and 2 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"The sample dataset is containing\", data_words.shape[0], \"lines and\", data_words.shape[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b46e0d-5d17-429b-982b-de22ae01dad3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9349f08e-3b0e-4f64-a190-9fdc57014cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 12:12:18.832345: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 12:12:18.893652: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-30 12:12:18.895532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-30 12:12:18.895540: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-30 12:12:19.294577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-30 12:12:19.294615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-30 12:12:19.294618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-30 12:12:19.522895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-30 12:12:19.522908: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-30 12:12:19.522919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sle-machina): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3970bd5-83e0-432a-b2c6-72572fcfdac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopW = stopwords.words('english')\n",
    "stopW.extend(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa972fae-02df-4458-8cc4-d282ebab84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SpaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "523a78a3-2244-4e76-b8c4-629795046889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer\n",
    "tokenizer = lambda text: [  # SpaCy Lemmatizer\n",
    "    token.lemma_.lower() for token in nlp(text) if token.is_alpha and not token.is_stop\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3673fba4-8c87-4a50-8bee-bcd3314e932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words[\"text\"] = data_words[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "496a1e2d-45e5-40d0-b392-22509d5fe286",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bidule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m truc \u001b[38;5;241m=\u001b[39m \u001b[43mbidule\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bidule' is not defined"
     ]
    }
   ],
   "source": [
    "truc = bidule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50ac4a-87be-48be-94e1-52bfed3294c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vectorization(method=\"tfidf\"):\n",
    "    if method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(strip_accents=\"unicode\", lowercase=True,\n",
    "                                     stop_words=stopW, tokenizer=tokenizer\n",
    "                                    )\n",
    "\n",
    "        X = vectorizer.fit_transform(data_words.text)\n",
    "        vocabulary = vectorizer.get_feature_names_out()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7e693-9b08-491f-a43d-bbd582658045",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b9168-201d-4509-bd8d-3e16e6b6d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents=\"unicode\", lowercase=True,\n",
    "                             stop_words=stopW, tokenizer=tokenizer\n",
    "                            )\n",
    "\n",
    "X = vectorizer.fit_transform(data_words.text)\n",
    "vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517072b8-cbfb-4975-8447-7192ae878193",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78d64258-ed80-42c1-976c-082f5cd0243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_words.text.apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5536206b-f3a5-4182-b3a2-3c1db59ce495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag documents for training\n",
    "X = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n",
    "\n",
    "# Train doc2vec model\n",
    "doc2vec = Doc2Vec()\n",
    "doc2vec.build_vocab(X)\n",
    "doc2vec.train(X, total_examples=doc2vec.corpus_count, epochs=doc2vec.epochs)\n",
    "\n",
    "# Vectorize text\n",
    "X = [doc2vec.infer_vector(doc.words) for doc in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8df52-6f40-4a95-bdb9-26da10b2d3ec",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88dd549-b61b-464e-8865-0f7dd91a135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_lsa,\n",
    "    data_words.target,\n",
    "    test_size=0.2,\n",
    "    stratify=data_words.target,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6da7bf-63c1-4e12-901a-ca2ceacf73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd55ba-a53a-40ce-987a-e70e21a52d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c4698-aea0-448a-b428-947a61e5d7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fcbe5-6f92-44e1-9943-6bf691573c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c4f1b-51f7-4aae-82be-74c82ce3ed29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212068e-fe94-41ae-a02d-c6782c3b00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "truc = bidule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38d84f-f693-4dc1-b624-2d69c6e7c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_language_processing(\n",
    "    df, col, stem_or_lemma=\"stem\", tags_to_remove=[], words_to_exclude=[],\n",
    "    max_threshold=999, min_threshold=0, word_cloud=True, debug=False):\n",
    "    \"\"\"Compute NLP preprocessing methods\n",
    "    \n",
    "    Parameters:\n",
    "    df (dataframe): input dataframe\n",
    "    col (str): column to process\n",
    "    stem_or_lemma (str): choose between stemmation or lemmatization\n",
    "    tags_to_remove list(str): a list of POS tag\n",
    "    words_to_exclude list(str): a list of words\n",
    "    max_threshold (int): upper threshold to filter word frequency\n",
    "    min_threshold (int): lower threshold to filter word frequency\n",
    "    word_cloud (bool): display WordCloud representation\n",
    "    debug (bool): show debug elements\n",
    "    \n",
    "    Returns:\n",
    "    list(list(str)): return a list of document. Each document is a list of words    \n",
    "    \"\"\"\n",
    "    # df = input_df.copy()\n",
    "    df[col] = df[col].apply(clean_text)\n",
    "    \n",
    "    # preprocessing part\n",
    "    preproc_res = preprocessing_words(df, col, stem_or_lemma=stem_or_lemma, debug=debug)\n",
    "    df.insert(0, 'preproc_text', preproc_res)\n",
    "    # if debug:\n",
    "    #     display(df[[col, 'preproc_text']].head())\n",
    "    \n",
    "    # filter by pos tag part\n",
    "    filtpos_res = filter_pos_tag(df, \"preproc_text\", tags_to_remove=tags_to_remove, debug=debug)\n",
    "    df.insert(0, 'filtpos_text', filtpos_res)\n",
    "    # if debug:\n",
    "    #     display(df[[col, 'preproc_text', 'filtpos_text']].head())\n",
    "    \n",
    "    # filter by excluding words\n",
    "    filtexcl_words = filter_exclude_words(df, \"filtpos_text\", words_to_exclude=words_to_exclude, debug=debug)\n",
    "    df.insert(0, 'filtexcl_words', filtexcl_words)\n",
    "    \n",
    "    if debug:\n",
    "        display(df[[col, 'preproc_text', 'filtpos_text', 'filtexcl_words']].head())\n",
    "    \n",
    "    # concatenate all documents into a single corpus\n",
    "    corpus = df[\"filtexcl_words\"].tolist()\n",
    "    corpus = [item for sublist in corpus for item in sublist]\n",
    "    \n",
    "    word_counts = Counter(corpus)\n",
    "    print(\"Il y a un total de\", len(word_counts), \"mots différents dans tout le corpus.\")\n",
    "    word_counts_threshold = {x: count for x, count in word_counts.items() if count > min_threshold}\n",
    "    word_counts_threshold = {x: count for x, count in word_counts_threshold.items() if count < max_threshold}\n",
    "    print(\"Après filtrage, on garde les mots aparaissant plus de\", min_threshold,\n",
    "          \"fois et moins de\", max_threshold, \"fois. Il reste alors\",\n",
    "          len(word_counts_threshold), \"mots différents dans tout le corpus.\\n\")\n",
    "    word_counts = Counter(word_counts_threshold)\n",
    "    # print(word_counts)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"------------ Top 20 plus communs : ------------\")\n",
    "        display_most_common = [(i, word_counts[i], word_counts[i] / len(corpus) * 100.0) for i, count in word_counts.most_common(20)]\n",
    "        for elt in display_most_common:\n",
    "            print(elt)\n",
    "        print(\"\\n------------ Top 20 moins communs : ------------\")\n",
    "        display_least_common = [(i, word_counts[i], word_counts[i] / len(corpus) * 100.0) for i, count in word_counts.most_common()[-20:]]\n",
    "        for elt in display_least_common:\n",
    "            print(elt)\n",
    "        \n",
    "    simplified_corpus = word_counts_threshold.keys()\n",
    "    \n",
    "    # display wordcloud part\n",
    "    if word_cloud:\n",
    "        display_wordcloud(word_counts_threshold, debug=debug)\n",
    "    \n",
    "    return simplified_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc379d10-e910-4d80-bfd8-fcac046de8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ponctuation restante dans le top 10\n",
    "# words_to_exclude = [\n",
    "#     \"``\", \"''\", \".\", \"..\", \"...\", \"....\", \".....\"\n",
    "# ]\n",
    "# # mots à supprimer\n",
    "# words_to_exclude += [\n",
    "#     \"get\", \"like\", \"go\", \"come\", \"take\", \"try\", \"told\", \"look\", \"another\", \"way\",\n",
    "#     \"restaurant\", \"thing\", \"wife\", \"husband\", \"u\", \"meal\", \"friend\", \"eat\"\n",
    "# ]\n",
    "# tags_to_remove=[\"JJ\", \"RB\", \"MD\", \"POS\", \"CD\", \":\", \"PRP\", \"VBP\"]\n",
    "\n",
    "# corpus = natural_language_processing(\n",
    "#     data_words, \"text\", stem_or_lemma=\"lemma\", words_to_exclude=words_to_exclude,\n",
    "#     tags_to_remove=tags_to_remove, max_threshold=1000, min_threshold=200, debug=False)\n",
    "\n",
    "\n",
    "corpus = natural_language_processing(data_words, \"text\", stem_or_lemma=\"lemma\", debug=False, word_cloud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9984b04-0eaa-4b43-9502-5575ed9e5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat, features_names = representation_by_tf_idf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a4557-1a79-44b7-bf1d-21567aefedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparation des données pour l'optimisation\n",
    "documents = data_words[\"filtexcl_words\"].tolist()\n",
    "simplified_documents = []\n",
    "for doc in documents:\n",
    "    simplified_documents.append([x for x in doc if x in corpus])\n",
    "dictionary = Dictionary(simplified_documents)\n",
    "corpus_gensim = [dictionary.doc2bow(doc) for doc in simplified_documents]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338257c-2afb-4bd7-a483-8c34d25add23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_W2V = representation_by_word2vec(simplified_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f313540-0132-4412-828c-f46b08d53491",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Detect topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef77ca-d800-4735-93a2-8cb36fa84e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Train LSA model\n",
    "n_components = 50\n",
    "lsa = TruncatedSVD(n_components=n_components, random_state=42).fit(tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15568a1-e2dd-407e-b3cb-434e066a87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explained variance ratio of LSA\n",
    "fig = px.line(\n",
    "    x=range(1, n_components + 1),\n",
    "    y=lsa.explained_variance_ratio_,\n",
    "    title=\"Explained variance ratio of LSA\",\n",
    "    labels={\"x\": \"Component\", \"y\": \"Explained variance ratio\"},\n",
    "    markers=True,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9e7c9-11b6-4e09-bb13-301b01f584ba",
   "metadata": {},
   "source": [
    "Elbow method 5 topics semble t il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9e6ba-9e5e-48de-ac6f-6c1d39028552",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=5, random_state=42).fit(tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0131c-fbc0-4f64-b5f5-9cb650ea2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lsa = lsa.transform(tfidf_mat)\n",
    "X_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7f04e-90c9-4c33-84a6-50fb68101e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d4c05-3253-422d-b353-cc88fdd6ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(lsa, features_names, 10, \"Topics in NMF model (Frobenius norm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ab2bc-0d7a-4b52-9010-94c3d12f5d7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8cf15-5145-448b-9685-7396495e90cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c7e79-4ba1-4f7d-af67-4010f50e934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation_by_tf_idf_bis(corpus):\n",
    "    \"\"\"Compute corpus into a tf-idf vectorisation\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (list(list(str)): a list of documents\n",
    "    \n",
    "    Returns:\n",
    "    a matrix of TF-IDF features\n",
    "    the list of features names\n",
    "    \"\"\"\n",
    "    vect = TfidfVectorizer(ngram_range=(1, 1))\n",
    "    tfidf_mat = vect.fit_transform(corpus)\n",
    "    features_names = vect.get_feature_names_out()\n",
    "    return tfidf_mat, features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096fb11-2e7c-4b1f-8f77-e2426fe41d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat, features_names = representation_by_tf_idf_bis(data_words.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3eb43-fc9c-436f-a73d-a7872e695858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf_mat,\n",
    "    data_words.target,\n",
    "    test_size=0.2,\n",
    "    stratify=data_words.target,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2903a9-561b-4909-afba-94b91249d9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegressionCV(random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bd043-b9fd-44bc-8de3-5386813cd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dea391-d21c-4a74-93bb-8a112b10e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87312544-4d49-4e9d-a13f-8dc4c28ca56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e893224-b1b4-4094-92a7-6dbc1907cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_confusion_matrix(actual_class=y_test, predict_class=y_pred, display_labels=[\"Negative\", \"Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675f6e1-3657-4a5b-8d2f-e3f693a41571",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_classification_report(actual_class=y_test, predict_class=y_pred, display_labels=[\"Negative\", \"Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7843e8-90c7-4082-b3d1-2ba18c40b209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf04fb-27a2-428c-9518-251fc71be9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model_name, y_test, y_test_pred):  \n",
    "    print(\"Calcul et affichage de la courbe ROC\")\n",
    "    [fpr_te, tpr_te, thr_te] = metrics.roc_curve(y_test, y_test_pred)#, pos_label=1)\n",
    "    plt.plot(fpr_te, tpr_te, color='coral', lw=2, label=\"\")\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('1 - Specificity', fontsize=14)\n",
    "    plt.ylabel('Sensitivity', fontsize=14)\n",
    "    plt.title(\"ROC du classifier {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0395560-1f27-42d8-a8ac-9ab74493fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(\"my model\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3323981-18cc-472a-9ef7-08156d12bc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_prj07",
   "language": "python",
   "name": "conda_env_prj07"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
